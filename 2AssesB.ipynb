{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2AssesB.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPm+FzodPDq7hTqIr1kkaL3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmaxwell/UniNotebooks/blob/master/2AssesB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETnvMsxWW2-_",
        "colab_type": "code",
        "outputId": "946f87e9-ea2c-41b2-a918-4133c00facfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install scattertext"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scattertext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/ef/6d7b23f6c431dd49f882926ab9bf5faba9dc416918a9ccdbb379c5e90066/scattertext-0.0.2.62-py3-none-any.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 9.3MB/s \n",
            "\u001b[?25hCollecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from scattertext) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from scattertext) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.18.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.0.3)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->scattertext) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->scattertext) (0.14.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->scattertext) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->scattertext) (2.8.1)\n",
            "Installing collected packages: mock, scattertext\n",
            "Successfully installed mock-4.0.2 scattertext-0.0.2.62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLFtqMZP4LTr",
        "colab_type": "code",
        "outputId": "774cb6d1-0cbd-4436-8d33-b9f461e422cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!pip install \"git+https://github.com/facebookresearch/fastText.git\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/fastText.git\n",
            "  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-ru0og55q\n",
            "  Running command git clone -q https://github.com/facebookresearch/fastText.git /tmp/pip-req-build-ru0og55q\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (1.18.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2871262 sha256=af7db4f0e64592d32ba9c037c0305cdd601cdfe2c862779433e3bcee68281d8b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ycnfdviu/wheels/69/f8/19/7f0ab407c078795bc9f86e1f6381349254f86fd7d229902355\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K_qm9qaXGM_",
        "colab_type": "text"
      },
      "source": [
        "Install all necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Hmw7ETW_af",
        "colab_type": "code",
        "outputId": "32500cb2-2569-46c0-b4eb-be0abd2affbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import fasttext.util\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import scattertext as st\n",
        "import spacy\n",
        "\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from scattertext import CorpusFromPandas, produce_scattertext_explorer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5lT_VeNXUZ4",
        "colab_type": "text"
      },
      "source": [
        "Read in data and look at first item"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBNz2bCXW_68",
        "colab_type": "code",
        "outputId": "5c384745-e083-495e-80c7-c06b9f2c6332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df = pd.read_csv('agr_en_train.csv', names=['unique_id','text','aggression-level'], sep=',')\n",
        "print(df.iloc[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique_id                                 facebook_corpus_msr_1723796\n",
            "text                Well said sonu..you have courage to stand agai...\n",
            "aggression-level                                                  OAG\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkedasNbiFdn",
        "colab_type": "text"
      },
      "source": [
        "Check for missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RGyKGNhXAXr",
        "colab_type": "code",
        "outputId": "2dcf5cfa-6d75-4751-fd1c-fc7ede9088bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.isna().values.any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9lH64z_iQR_",
        "colab_type": "text"
      },
      "source": [
        "Count the occurrences per Aggression Level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBKduKwWiJBt",
        "colab_type": "code",
        "outputId": "562e9ece-141d-4989-b456-be89a3d50668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df['aggression-level'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NAG    5051\n",
              "CAG    4240\n",
              "OAG    2708\n",
              "Name: aggression-level, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCA0L0_9iZxJ",
        "colab_type": "text"
      },
      "source": [
        "Identify the top occurring words per Aggression Level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "theMyQE6iJwz",
        "colab_type": "code",
        "outputId": "1ba40bf6-a968-440e-86d8-ba34c263dac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "df['parsed'] = df.text.apply(nlp)\n",
        "data = st.CorpusFromParsedDocuments(df, category_col='aggression-level', \n",
        "                                      parsed_col='parsed').build().remove_terms(nlp.Defaults.stop_words, ignore_absences=True)\n",
        "\n",
        "freq_df = data.get_term_freq_df()\n",
        "oag_tw = freq_df.sort_values(by=['OAG freq'], ascending=False)\n",
        "oag_tw = oag_tw.drop(oag_tw.columns[[1,2]], axis=1)\n",
        "nag_tw = freq_df.sort_values(by=['NAG freq'], ascending=False)\n",
        "nag_tw = nag_tw.drop(nag_tw.columns[[0,2]], axis=1)\n",
        "cag_tw = freq_df.sort_values(by=['CAG freq'], ascending=False)\n",
        "cag_tw = cag_tw.drop(cag_tw.columns[[0,1]], axis=1)\n",
        "\n",
        "print(oag_tw.head())\n",
        "print(nag_tw.head())\n",
        "print(cag_tw.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        OAG freq\n",
            "term            \n",
            "u            420\n",
            "india        396\n",
            "people       372\n",
            "like         317\n",
            "indian       279\n",
            "        NAG freq\n",
            "term            \n",
            "india        616\n",
            "people       357\n",
            "good         355\n",
            "indian       350\n",
            "like         315\n",
            "        CAG freq\n",
            "term            \n",
            "people       554\n",
            "india        493\n",
            "u            466\n",
            "bjp          357\n",
            "like         337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfu4-4Qvsg-s",
        "colab_type": "text"
      },
      "source": [
        "Replace the text labels with values and save as a vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fal8prKFiKR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['aggression-level'] = df['aggression-level'].replace({ 'OAG' : 0, 'NAG' : 1, 'CAG' : 2 }) \n",
        "labels = df['aggression-level'].values\n",
        "labels = to_categorical(labels, num_classes = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oapR1uNkGpLX",
        "colab_type": "text"
      },
      "source": [
        "Load the fasttext model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW4W9rBzGnJ2",
        "colab_type": "code",
        "outputId": "4672e3f8-f7bf-48c3-a345-a6ea8e8dc14e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "fasttext.util.download_model('en', if_exists='ignore') \n",
        "ft = fasttext.load_model('cc.en.300.bin')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaAG2z04K8A9",
        "colab_type": "text"
      },
      "source": [
        "Set the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhwFxDeeiKr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_length = 50\n",
        "data_count = len(df)\n",
        "dims = ft.get_dimension()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GrQLQfojuLY",
        "colab_type": "text"
      },
      "source": [
        "Sub-function to clean the text, remove all non-ASCII characters and split to individual words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVVTII1XjzVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_up(text):\n",
        " \n",
        "  text = text.replace('&', ' and ')\n",
        "  text = text.replace('@', ' at ')\n",
        "  text = re.sub(r'[^\\x41-\\x7f]',r' ',text)\n",
        "  text = text.lower().split()\n",
        "\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l2NBvSzepsj",
        "colab_type": "text"
      },
      "source": [
        "Sub-function to create the vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NKO26wQerGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_vector(text):\n",
        "\n",
        "    text = normalize(text)\n",
        "    words = text.split()\n",
        "    window = words[-review_length:]\n",
        "    \n",
        "    x = np.zeros((review_length, dims))\n",
        "\n",
        "    for i, word in enumerate(window):\n",
        "        x[i, :] = ft.get_word_vector(word).astype('float32')\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LACbBOSSer9A",
        "colab_type": "text"
      },
      "source": [
        "Function to take the text from the review column, clean it, turn it to individual words then convert to vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIwDnEta4xQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def df_to_data(df):\n",
        "    \"\"\"\n",
        "    Convert a given dataframe to a dataset of inputs for the NN.\n",
        "    \"\"\"\n",
        "    x = np.zeros((len(df), review_length, dims), dtype='float32')\n",
        "\n",
        "    for i, comment in enumerate(df['text'].values):\n",
        "        x[i, :] = text_to_vector(comment)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbazWJh5KIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = df_to_data(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuociVY_5vyM",
        "colab_type": "code",
        "outputId": "a2287ebb-87ee-463a-9f8d-cb38a32b0bf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11999, 50, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfyXv14B6cz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(embedding, labels, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOKrWPHJ8Q-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCeeog2K6qjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_text_classifier():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv1D(128, 5, activation='relu', input_shape=(50, 300)))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(10, activation='relu'))\n",
        "    model.add(layers.Dense(3, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US3b2CqE8Es9",
        "colab_type": "code",
        "outputId": "6228194b-25a3-44f2-f323-9caa45412eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model = cnn_text_classifier()\n",
        "training = model.fit(X_train, y_train, epochs=10, verbose=False, validation_data=(X_test, y_test), batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_9 (Conv1D)            (None, 46, 128)           192128    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_8 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 3)                 33        \n",
            "=================================================================\n",
            "Total params: 193,451\n",
            "Trainable params: 193,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_O6ozD2Cwv3",
        "colab_type": "code",
        "outputId": "33ec7f5d-9157-4895-f3ed-9cdcc783964a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9535\n",
            "Testing Accuracy:  0.5167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yglXUt8HSwiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}