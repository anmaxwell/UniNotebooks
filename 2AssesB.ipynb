{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2AssesB.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPCKayS6iXs8c7ggGjDtFSK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmaxwell/UniNotebooks/blob/master/2AssesB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETnvMsxWW2-_",
        "colab_type": "code",
        "outputId": "e8768763-0462-4c53-fe69-7954e7bf41b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!pip install scattertext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scattertext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/ef/6d7b23f6c431dd49f882926ab9bf5faba9dc416918a9ccdbb379c5e90066/scattertext-0.0.2.62-py3-none-any.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from scattertext) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.18.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.12.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from scattertext) (0.10.2)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->scattertext) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->scattertext) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->scattertext) (2018.9)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->scattertext) (0.5.1)\n",
            "Installing collected packages: mock, scattertext\n",
            "Successfully installed mock-4.0.2 scattertext-0.0.2.62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLFtqMZP4LTr",
        "colab_type": "code",
        "outputId": "8f1464ae-4138-4a17-9266-3ad578a6dec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install \"git+https://github.com/facebookresearch/fastText.git\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/fastText.git\n",
            "  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-rilwkie1\n",
            "  Running command git clone -q https://github.com/facebookresearch/fastText.git /tmp/pip-req-build-rilwkie1\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (1.18.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2871344 sha256=3c8e5fe6607ede388be29972160004ffe6763cbe509d233acfc12dfa21ce4a20\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zc48qp7h/wheels/69/f8/19/7f0ab407c078795bc9f86e1f6381349254f86fd7d229902355\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K_qm9qaXGM_",
        "colab_type": "text"
      },
      "source": [
        "Install all necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Hmw7ETW_af",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0ef3650-919a-45e7-d679-e9817d486209"
      },
      "source": [
        "import fasttext.util\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import scattertext as st\n",
        "import spacy\n",
        "\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from scattertext import CorpusFromPandas, produce_scattertext_explorer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5lT_VeNXUZ4",
        "colab_type": "text"
      },
      "source": [
        "Read in data and look at first item"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBNz2bCXW_68",
        "colab_type": "code",
        "outputId": "f4b91539-c969-4929-c2c2-50e6e0bd2aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df = pd.read_csv('agr_en_train.csv', names=['unique_id','text','aggression-level'], sep=',')\n",
        "print(df.iloc[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique_id                                 facebook_corpus_msr_1723796\n",
            "text                Well said sonu..you have courage to stand agai...\n",
            "aggression-level                                                  OAG\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkedasNbiFdn",
        "colab_type": "text"
      },
      "source": [
        "Check for missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RGyKGNhXAXr",
        "colab_type": "code",
        "outputId": "c290d2ba-b891-494c-868e-6243ead77389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.isna().values.any()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9lH64z_iQR_",
        "colab_type": "text"
      },
      "source": [
        "Count the occurrences per Aggression Level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBKduKwWiJBt",
        "colab_type": "code",
        "outputId": "83ec735b-a655-49a5-f80d-d933b4ac05f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df['aggression-level'].value_counts() "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NAG    5051\n",
              "CAG    4240\n",
              "OAG    2708\n",
              "Name: aggression-level, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCA0L0_9iZxJ",
        "colab_type": "text"
      },
      "source": [
        "Identify the top occurring words per Aggression Level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "theMyQE6iJwz",
        "colab_type": "code",
        "outputId": "74782532-4860-493a-e92b-ffe2eda27a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "df['parsed'] = df.text.apply(nlp)\n",
        "data = st.CorpusFromParsedDocuments(df, category_col='aggression-level', \n",
        "                                      parsed_col='parsed').build().remove_terms(nlp.Defaults.stop_words, ignore_absences=True)\n",
        "\n",
        "freq_df = data.get_term_freq_df()\n",
        "oag_tw = freq_df.sort_values(by=['OAG freq'], ascending=False)\n",
        "oag_tw = oag_tw.drop(oag_tw.columns[[1,2]], axis=1)\n",
        "nag_tw = freq_df.sort_values(by=['NAG freq'], ascending=False)\n",
        "nag_tw = nag_tw.drop(nag_tw.columns[[0,2]], axis=1)\n",
        "cag_tw = freq_df.sort_values(by=['CAG freq'], ascending=False)\n",
        "cag_tw = cag_tw.drop(cag_tw.columns[[0,1]], axis=1)\n",
        "\n",
        "print(oag_tw.head())\n",
        "print(nag_tw.head())\n",
        "print(cag_tw.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        OAG freq\n",
            "term            \n",
            "u            420\n",
            "india        396\n",
            "people       372\n",
            "like         317\n",
            "indian       279\n",
            "        NAG freq\n",
            "term            \n",
            "india        616\n",
            "people       357\n",
            "good         355\n",
            "indian       350\n",
            "like         315\n",
            "        CAG freq\n",
            "term            \n",
            "people       554\n",
            "india        493\n",
            "u            466\n",
            "bjp          357\n",
            "like         337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfu4-4Qvsg-s",
        "colab_type": "text"
      },
      "source": [
        "Replace the text labels with values and save as a vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fal8prKFiKR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['aggression-level'] = df['aggression-level'].replace({ 'OAG' : 0, 'NAG' : 1, 'CAG' : 2 }) \n",
        "labels = df['aggression-level'].values\n",
        "labels = to_categorical(labels, num_classes = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oapR1uNkGpLX",
        "colab_type": "text"
      },
      "source": [
        "Load the fasttext model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW4W9rBzGnJ2",
        "colab_type": "code",
        "outputId": "62ce7e59-8f38-4513-b2bc-31a313c36976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "fasttext.util.download_model('en', if_exists='ignore') \n",
        "ft = fasttext.load_model('cc.en.300.bin')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaAG2z04K8A9",
        "colab_type": "text"
      },
      "source": [
        "Set the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhwFxDeeiKr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_length = 100\n",
        "data_count = len(df)\n",
        "dims = ft.get_dimension()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l2NBvSzepsj",
        "colab_type": "text"
      },
      "source": [
        "Function to take the text from the review column, clean it, turn it to individual words then convert to vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NKO26wQerGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_vector(text):\n",
        "\n",
        "  text = text.replace('&', ' and ')\n",
        "  text = text.replace('@', ' at ')\n",
        "  text = re.sub(r'[^\\x41-\\x7f]',r' ',text)\n",
        "  text = text.lower().split()\n",
        "\n",
        "  window = text[-review_length:]\n",
        "  \n",
        "  vectors = np.zeros((review_length, dims))\n",
        "\n",
        "  for i, word in enumerate(window):\n",
        "      vectors[i, :] = ft.get_word_vector(word).astype('float32')\n",
        "\n",
        "  return vectors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LACbBOSSer9A",
        "colab_type": "text"
      },
      "source": [
        "Function to create the word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIwDnEta4xQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_word_embedding(df):\n",
        "\n",
        "    word_embedding = np.zeros((len(df), review_length, dims), dtype='float32')\n",
        "\n",
        "    for i, review in enumerate(df['text'].values):\n",
        "        word_embedding[i, :] = text_to_vector(review)\n",
        "\n",
        "    return word_embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm4YTsnyg1YN",
        "colab_type": "text"
      },
      "source": [
        "Create the embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbazWJh5KIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = create_word_embedding(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiXOm77HhABk",
        "colab_type": "text"
      },
      "source": [
        "Create the training and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfyXv14B6cz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(embedding, labels, test_size=0.20, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCbBM3Goisht",
        "colab_type": "text"
      },
      "source": [
        "Create the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCeeog2K6qjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_text_classifier():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv1D(128, 5, activation='relu', input_shape=(review_length, dims)))\n",
        "    model.add(layers.GlobalAveragePooling1D())\n",
        "    model.add(layers.Dense(10, activation='relu'))\n",
        "    model.add(layers.Dense(3, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heFRdX44i7d9",
        "colab_type": "text"
      },
      "source": [
        "Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US3b2CqE8Es9",
        "colab_type": "code",
        "outputId": "4c7c14f4-4cd5-4c42-e670-dad6d6d3d634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "model = cnn_text_classifier()\n",
        "model.fit(X_train, y_train, epochs=10, verbose=False, validation_data=(X_test, y_test), batch_size=10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_5 (Conv1D)            (None, 96, 128)           192128    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_5 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 33        \n",
            "=================================================================\n",
            "Total params: 193,451\n",
            "Trainable params: 193,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f62f1643da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mAyPgjKi_GA",
        "colab_type": "text"
      },
      "source": [
        "Check the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_O6ozD2Cwv3",
        "colab_type": "code",
        "outputId": "b7db766e-4560-465d-ae1d-a2ffdb79b0d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.5933\n",
            "Testing Accuracy:  0.5433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yglXUt8HSwiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}