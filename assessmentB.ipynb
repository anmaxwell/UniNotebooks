{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assessmentB.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPeNfrjVUvqOmI6dgtJa75Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmaxwell/UniNotebooks/blob/master/assessmentB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw28IlWpZhh5",
        "colab_type": "text"
      },
      "source": [
        "To develop a classifier with Convolutional Neural Networks, we need to follow the following steps:\n",
        "1. We then need to split the data into training and testing and extract features. \n",
        "2. Then we need to define the architecture of the convolutional neural network.\n",
        "3. Then we need to train the model, and finally,\n",
        "4. Evaluate it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVwHLgjXZMkd",
        "colab_type": "code",
        "outputId": "a3a9b712-109b-4a39-c577-b9fead242eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install scattertext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scattertext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/ef/6d7b23f6c431dd49f882926ab9bf5faba9dc416918a9ccdbb379c5e90066/scattertext-0.0.2.62-py3-none-any.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from scattertext) (0.10.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from scattertext) (0.25.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.12.0)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from scattertext) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.18.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->scattertext) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->scattertext) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->scattertext) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->scattertext) (0.14.1)\n",
            "Installing collected packages: mock, scattertext\n",
            "Successfully installed mock-4.0.2 scattertext-0.0.2.62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA1Hww5rI8bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import scattertext as st\n",
        "import spacy\n",
        "\n",
        "from scattertext import CorpusFromPandas, produce_scattertext_explorer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hFL4KRlZrpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read data into a dataframe\n",
        "df = pd.read_csv('agr_en_train.csv', names=['unique_id','text','aggression-level'], sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDhRHvMPZsLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove the unique_ID column\n",
        "df = df.drop(df.columns[[0]], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsEg-Z_gZslA",
        "colab_type": "code",
        "outputId": "820b0068-ddea-44ee-e867-a396ba1c43e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#check for missing values\n",
        "df.isna().values.any()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFvWKaDabvs4",
        "colab_type": "code",
        "outputId": "fc39f938-7672-45ab-d18d-56f7c1efc1d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#count the occurences of each level of aggression\n",
        "df['aggression-level'].value_counts() "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NAG    5051\n",
              "CAG    4240\n",
              "OAG    2708\n",
              "Name: aggression-level, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVbZrLe4b5fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare the data??\n",
        "nlp = spacy.load('en')\n",
        "df['parsed'] = df.text.apply(nlp)\n",
        "corpus = st.CorpusFromParsedDocuments(df, category_col='aggression-level', \n",
        "                                      parsed_col='parsed').build().remove_terms(nlp.Defaults.stop_words, ignore_absences=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze2FFq9wetpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq_df = corpus.get_term_freq_df()\n",
        "oag_tw = freq_df.sort_values(by=['OAG freq'], ascending=False)\n",
        "oag_tw = oag_tw.drop(oag_tw.columns[[1,2]], axis=1)\n",
        "nag_tw = freq_df.sort_values(by=['NAG freq'], ascending=False)\n",
        "nag_tw = nag_tw.drop(nag_tw.columns[[0,2]], axis=1)\n",
        "cag_tw = freq_df.sort_values(by=['CAG freq'], ascending=False)\n",
        "cag_tw = cag_tw.drop(cag_tw.columns[[0,1]], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpfGyx6neuMZ",
        "colab_type": "code",
        "outputId": "6a6627cd-9b6d-4e4a-9888-8a2672c2fbbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "print(oag_tw.head())\n",
        "print(nag_tw.head())\n",
        "print(cag_tw.head())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        OAG freq\n",
            "term            \n",
            "u            420\n",
            "india        396\n",
            "people       372\n",
            "like         317\n",
            "indian       279\n",
            "        NAG freq\n",
            "term            \n",
            "india        616\n",
            "people       357\n",
            "good         355\n",
            "indian       350\n",
            "like         315\n",
            "        CAG freq\n",
            "term            \n",
            "people       554\n",
            "india        493\n",
            "u            466\n",
            "bjp          357\n",
            "like         337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ygz0QNipAtA",
        "colab_type": "code",
        "outputId": "4778c007-394b-493e-e02e-1ecd725f9d48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "# define the document\n",
        "text = 'The quick brown fox jumped over the lazy dog.'\n",
        "# tokenize the document\n",
        "result = text_to_word_sequence(text)\n",
        "print(result)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8E7qjiiN89-",
        "colab_type": "code",
        "outputId": "884f27e5-db25-433b-f120-e25ed1d81b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "new_freq_df = corpus.get_term_freq_result()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-06fb908ed19f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_freq_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_term_freq_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'ParsedCorpus' object has no attribute 'get_term_freq_result'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: Current TensorFlow version is 2.2.0-rc1. To use TF 1.x instead,\nrestart your runtime (Ctrl+M .) and run \"%tensorflow_version 1.x\" before\nyou run \"import tensorflow\".\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lJUBe7SsB7U",
        "colab_type": "code",
        "outputId": "3f65278c-1a6a-47e9-b656-a5141c9dbdf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# create the tokenizer\n",
        "t = Tokenizer()\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(result)\n",
        "# summarize what was learned\n",
        "print(t.word_counts)\n",
        "print(t.document_count)\n",
        "print(t.word_index)\n",
        "print(t.word_docs)\n",
        "# integer encode documents\n",
        "encoded_docs = t.texts_to_matrix(result, mode='count')\n",
        "print(encoded_docs)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('the', 2), ('quick', 1), ('brown', 1), ('fox', 1), ('jumped', 1), ('over', 1), ('lazy', 1), ('dog', 1)])\n",
            "9\n",
            "{'the': 1, 'quick': 2, 'brown': 3, 'fox': 4, 'jumped': 5, 'over': 6, 'lazy': 7, 'dog': 8}\n",
            "defaultdict(<class 'int'>, {'the': 2, 'quick': 1, 'brown': 1, 'fox': 1, 'jumped': 1, 'over': 1, 'lazy': 1, 'dog': 1})\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAcqkLW_sCYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}