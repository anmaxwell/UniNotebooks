{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workissues.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOvE1muPPP0E3VEi13X5HKT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmaxwell/UniNotebooks/blob/master/workissues.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLFtqMZP4LTr",
        "colab_type": "code",
        "outputId": "4f1d97bc-2089-4052-c0f0-13c8505ee2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "!pip install \"git+https://github.com/facebookresearch/fastText.git\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/fastText.git\n",
            "  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-7nr280vq\n",
            "  Running command git clone -q https://github.com/facebookresearch/fastText.git /tmp/pip-req-build-7nr280vq\n",
            "Requirement already satisfied (use --upgrade to upgrade): fasttext==0.9.2 from git+https://github.com/facebookresearch/fastText.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (1.18.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3005626 sha256=6b022b86bff816a346099f0d883372f6c7aef817384a36e9e52067638f16bab8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4fcyvf47/wheels/69/f8/19/7f0ab407c078795bc9f86e1f6381349254f86fd7d229902355\n",
            "Successfully built fasttext\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K_qm9qaXGM_",
        "colab_type": "text"
      },
      "source": [
        "Install all necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Hmw7ETW_af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fasttext.util\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from keras import layers\n",
        "from keras.layers import Dropout \n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5lT_VeNXUZ4",
        "colab_type": "text"
      },
      "source": [
        "Read in data and look at first item"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBNz2bCXW_68",
        "colab_type": "code",
        "outputId": "69724a1b-6d1b-4708-de9f-15c6518ec5d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df = pd.read_csv('ModelData.csv', names=['text','issue'], sep=',')\n",
        "print(df.iloc[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text     install sent otdl\n",
            "issue                    0\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfu4-4Qvsg-s",
        "colab_type": "text"
      },
      "source": [
        "Create labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fal8prKFiKR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df['issue'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oapR1uNkGpLX",
        "colab_type": "text"
      },
      "source": [
        "Load the fasttext model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW4W9rBzGnJ2",
        "colab_type": "code",
        "outputId": "6a52f4a2-a2f3-4c2b-96e7-a03df443df0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "fasttext.util.download_model('en', if_exists='ignore') \n",
        "ft = fasttext.load_model('cc.en.300.bin')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaAG2z04K8A9",
        "colab_type": "text"
      },
      "source": [
        "Set the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhwFxDeeiKr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_length = 150\n",
        "data_count = len(df)\n",
        "dims = ft.get_dimension()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l2NBvSzepsj",
        "colab_type": "text"
      },
      "source": [
        "Function to take the text from the review column, clean it, turn it to individual words then convert to vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NKO26wQerGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_vector(text):\n",
        "\n",
        "  text = text.replace('&', ' and ')\n",
        "  text = text.replace('@', ' at ')\n",
        "  text = re.sub(r'[^\\x41-\\x7f]',r' ',text)\n",
        "  text = text.lower().split()\n",
        "\n",
        "  window = text[-review_length:]\n",
        "  \n",
        "  vectors = np.zeros((review_length, dims))\n",
        "\n",
        "  for i, word in enumerate(window):\n",
        "      vectors[i, :] = ft.get_word_vector(word).astype('float32')\n",
        "\n",
        "  return vectors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LACbBOSSer9A",
        "colab_type": "text"
      },
      "source": [
        "Function to create the word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIwDnEta4xQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_word_embedding(df):\n",
        "\n",
        "    word_embedding = np.zeros((len(df), review_length, dims), dtype='float32')\n",
        "\n",
        "    for i, review in enumerate(df['text'].values):\n",
        "        word_embedding[i, :] = text_to_vector(review)\n",
        "\n",
        "    return word_embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm4YTsnyg1YN",
        "colab_type": "text"
      },
      "source": [
        "Create the embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbazWJh5KIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = create_word_embedding(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiXOm77HhABk",
        "colab_type": "text"
      },
      "source": [
        "Create the training and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfyXv14B6cz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(embedding, labels, test_size=0.30, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCbBM3Goisht",
        "colab_type": "text"
      },
      "source": [
        "Create the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCeeog2K6qjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_text_classifier():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(review_length, dims)))\n",
        "    model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(layers.GlobalAveragePooling1D())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(layers.Dense(10, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heFRdX44i7d9",
        "colab_type": "text"
      },
      "source": [
        "Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US3b2CqE8Es9",
        "colab_type": "code",
        "outputId": "94582d8f-ca33-45c2-f1ce-6d83bf2aa470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model = cnn_text_classifier()\n",
        "history = model.fit(X_train, y_train, epochs=20, verbose=False, validation_data=(X_test, y_test), batch_size=10)\n",
        "model.save(\"model.h5\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 148, 128)          115328    \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 146, 64)           24640     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_4 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 140,629\n",
            "Trainable params: 140,629\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByeC_gcIiatO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "\n",
        "#files.download('model.h5')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mAyPgjKi_GA",
        "colab_type": "text"
      },
      "source": [
        "Check the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_O6ozD2Cwv3",
        "colab_type": "code",
        "outputId": "aa93f26d-4bbc-4f12-9d77-52d5ee409988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9111\n",
            "Testing Accuracy:  0.8630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LclbUv8zMHnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "82df4980-a89c-4dd3-9a71-5e66dc7914ee"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "y_pred1 = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred1, axis=1)\n",
        "\n",
        "# Print f1, precision, and recall scores\n",
        "print(\"Precision:\", precision_score(y_test, y_pred , average=\"macro\"))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred , average=\"macro\"))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred , average=\"macro\"))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.3798932384341637\n",
            "Recall: 0.5\n",
            "F1 score: 0.43174924165824063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UY41NqlhqR4",
        "colab_type": "text"
      },
      "source": [
        "Given the data is not evenly spread, looking at the F1 score gives a better understanding of how the model is performing.\n",
        "The score needs to be as close to 1 as possible to ensure that it is correctly identifying issues as issues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yglXUt8HSwiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(training):\n",
        "    acc = training.history['accuracy']\n",
        "    val_acc = training.history['val_accuracy']\n",
        "    loss = training.history['loss']\n",
        "    val_loss = training.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'g', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'y', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vhcCOyZ4AjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehnQfYDrI7qB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_predict(predictdf):\n",
        "  output_predictions = {}\n",
        "  comment_vector = create_word_embedding(predictdf)\n",
        "  issue_value = model.predict(comment_vector)\n",
        "  for i,item in enumerate(issue_value):\n",
        "    if item >0.5:\n",
        "      predictdf.at[i,'value'] = 'Issue'\n",
        "    else:\n",
        "      predictdf.at[i,'value'] = 'No Issue' \n",
        "  predictdf.to_csv('results.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-qOJ_H-M35D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXacR3-VLlUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KyNThVWLy1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}